// Speech API Protocol Buffer File
// This is the gRPC definition for the LumenVox Speech API

syntax = "proto3";

package lumenvox.api.speech.v1;

option csharp_namespace = "LumenVox.Api.Speech.V1";
option go_package = "lumenvox/api/speech/v1";
option java_multiple_files = false;
option java_outer_classname = "SpeechProto";
option java_package = "lumenvox.api.speech.v1";
option objc_class_prefix = "CLVOP";
option php_namespace = "LumenVox\\Api\\Speech\\V1";

// SpeechAPIService
//
// The LumenVox Speech API can be used to access various speech resources,
// such as Automatic Speech Recognition (ASR), Text-To-Speech (TTS),
// Transcription, Call-Progress-Analysis (CPA).
//
service SpeechAPIService {

  // ======== Session commands  ===============================================

  // SessionCreate
  //
  // Creates a new session and returns its ID and session related messages
  // through response stream
  //
  // The returned session_id (uuid) can be used when making other requests
  // for the session.
  //
  rpc SessionCreate(SessionCreateRequest)
      returns (stream SessionCreateResponse);

  // SessionClose
  //
  // Closes the specified session. Once closed, a session can no longer be
  // referenced for requests and should be assumed to be no longer valid.
  //
  rpc SessionClose(SessionCloseRequest)
      returns (SessionCloseResponse);

  // AudioStreamCreate
  //
  // Creates a new audio stream using the specified parameters.
  //
  // Only one audio stream can be created per session. Audio will be added
  // to this stream via gRPC (AudioStreamPush)
  //
  rpc AudioStreamCreate(AudioStreamCreateRequest)
      returns (AudioStreamCreateResponse);

  // AudioStreamPush
  //
  // Sends binary audio data into the specified audio stream.
  //
  // Note that this may be called before an interaction exists, so allows
  // audio streaming before creating interactions that will process the stream.
  //
  rpc AudioStreamPush(AudioStreamPushRequest)
      returns (AudioStreamPushResponse);

  // AudioStreamPull
  //
  // Gets audio data from an audio stream.
  //
  // A begin point in milliseconds and maximum length can be specified to
  // return a slice of the audio data.
  //
  // By default, all audio data within the stream is returned
  //
  rpc AudioStreamPull(AudioStreamPullRequest)
      returns (AudioStreamPullResponse);

  // SessionSetSettings
  //
  // Applies configuration changes to specified session settings.
  //
  rpc SessionSetSettings(SessionSetSettingsRequest)
      returns (SessionSetSettingsResponse);

  // SessionGetSettings
  //
  // Returns a JSON encoded string containing the requested session settings.
  //
  rpc SessionGetSettings(SessionGetSettingsRequest)
      returns (SessionGetSettingsResponse);

  // ======== Interaction Commands  ==========================================

  // InteractionCreateASR
  //
  // Creates a new ASR interaction for the specified session.
  //
  // This type of object is required to access ASR functionality. Use the
  // returned interaction_id in subsequent ASR requests.
  //
  rpc InteractionCreateASR(InteractionCreateASRRequest)
      returns (InteractionCreateASRResponse);

  // InteractionCreateTTS
  //
  // Creates a new TTS interaction for the specified session.
  //
  // This type of object is required to access TTS functionality. Use the
  // returned interaction_id in subsequent TTS requests.
  //
  rpc InteractionCreateTTS(InteractionCreateTTSRequest)
      returns (InteractionCreateTTSResponse);

  // InteractionCreateGrammarLoad
  //
  // Requests a grammar be loaded within the specified session/interaction.
  //
  // The returned interaction_id may be referenced in subsequent ASR requests.
  //
  rpc InteractionCreateGrammarLoad
      (InteractionCreateGrammarLoadRequest)
      returns (InteractionCreateGrammarLoadResponse);

  // InteractionCreateGrammarParse
  //
  // Create a new grammar parse interaction for the specified session.
  //
  // A grammar parse interaction allows sending text directly, to be parsed
  // by the active grammars.
  //
  // Essentially this is the same as an ASR interaction, but the speech to
  // text functionality is skipped.  The raw text is passed in directly
  // instead of having the ASR engine supply the text from the audio.
  // The text is parsed with the active grammars in
  // the same way as an ASR interaction.
  //
  // The returned interaction_id may be used to determine status of this
  // request as well as to access results, when processing is completed.
  //
  rpc InteractionCreateGrammarParse
      (InteractionCreateGrammarParseRequest)
      returns (InteractionCreateGrammarParseResponse);

  // InteractionSetSettings
  //
  // Adds or modifies the specified settings to the specified interaction.
  //
  // Settings not mentioned in this call will remain unaffected.
  //
  rpc InteractionSetSettings(InteractionSetSettingsRequest)
      returns (InteractionSetSettingsResponse);

  // InteractionGetSettings
  //
  // Return a JSON encoded string containing the current settings for the
  // specified interaction.
  //
  rpc InteractionGetSettings(InteractionGetSettingsRequest)
      returns (InteractionGetSettingsResponse);

  // InteractionBeginProcessing
  //
  // Begins processing the specified interaction.
  //
  // Typically, any interaction settings that are needed should be set before
  // calling InteractionBeginProcessing.
  //
  // Calling this function triggers backend services to begin processing the
  // audio or text being inputted
  //
  rpc InteractionBeginProcessing(InteractionBeginProcessingRequest)
      returns (InteractionBeginProcessingResponse);


  // InteractionFinalizeProcessing
  //
  // Used to force VAD complete when VAD is used, or after VAD speech begin.
  //
  // Takes all available stream audio and triggers an ASR decode. This is
  // optional most of the time, when the default auto-decode setting is used.
  //
  // This can also be used when performing DTMF or Text type interactions
  //
  // Results for the interaction may be available during subsequent calls to
  // InteractionRequestResults
  //
  rpc InteractionFinalizeProcessing(InteractionFinalizeProcessingRequest)
      returns (InteractionFinalizeProcessingResponse);

  // InteractionRequestResults
  //
  // Returns an interaction's results as a JSON encoded string.
  //
  // Note that an empty JSON object may be returned if no results are currently
  // available
  //
  rpc InteractionRequestResults(InteractionRequestResultsRequest)
      returns (InteractionRequestResultsResponse);

  // InteractionCancel
  //
  // Cancels the specified interaction. Any active processing related to the
  // interaction is stopped.
  //
  rpc InteractionCancel(InteractionCancelRequest)
      returns (InteractionCancelResponse);

  // InteractionClose
  //
  // Closes the specified interaction.
  //
  rpc InteractionClose(InteractionCloseRequest)
      returns (InteractionCloseResponse);
}

// ======== messages below  ===============================================

message SessionCreateRequest {
  // No parameters required
}

message SessionCreateResponse {

  // Responses will be in the form of streamed messages, and will be
  // one of the following types
  oneof response{
    // Session ID of newly created session (will be returned from initial call)
    string session_id = 1;

    // VAD Callback Messages
    VADMessage vad = 2;

    // Final Result Callback Messages
    InteractionFinalResultsReadyMessage result = 3;

    // Intermediate Result Callback Messages
    InteractionIntermediateResultsReady partial_result = 4;
  }
}

message SessionCloseRequest {
  // Reference to session to close
  string session_id = 1;
}

message SessionCloseResponse {
  // Currently no fields returned
}

message AudioFormat {
  // Specification for the audio format
  //
  // Not all standard formats are supported in all cases. Different
  // interactions can natively handle a subset of the total audio formats.
  //
  enum StandardAudioFormat {
    // Undefined audio
    STANDARD_AUDIO_FORMAT_UNSPECIFIED = 0;
    STANDARD_AUDIO_FORMAT_ULAW_8KHZ = 1;  // ULAW 8000 HZ, 1 byte per sample
    STANDARD_AUDIO_FORMAT_ALAW_8KHZ = 2;  // ALAW 8000 HZ, 1 byte per sample
    STANDARD_AUDIO_FORMAT_PCM_8KHZ = 3;   // PCM 8000 HZ, 2 bytes per sample
    STANDARD_AUDIO_FORMAT_PCM_16KHZ = 10; // PCM 16000 HZ, 2 bytes per sample
    STANDARD_AUDIO_FORMAT_PCM_22KHZ = 20; // PCM 22050 HZ, 2 bytes per sample
  }

  // Standard audio format
  StandardAudioFormat standard_audio_format  = 1;
}

message AudioStreamCreateRequest {
  // References an existing session_id (uuid)
  string session_id = 1;

  // Audio parameters for the stream object being created.
  // These audio parameters various attributes such as encoding format,
  // sample rate, etc.
  AudioFormat audio_format = 2;
}

message AudioStreamCreateResponse {
  // Currently no fields returned
}

message AudioStreamPushRequest {
  // References an existing session_id (uuid) to where the audio will be sent
  string session_id = 1;

  // Binary audio data to be added to the audio stream
  bytes stream_data = 3;
}

message AudioStreamPushResponse {
  // Currently no fields returned
}

message AudioStreamPullRequest {
  // References an existing session_id (uuid)
  string session_id = 1;

  // id of the audio requested (Note that this could be session_id to request
  // the inbound audio stream)
  string audio_id = 3;

  // Number of milliseconds from the beginning of the audio to return
  // (default is from the beginning)
  int64 audio_start = 5;

  // Maximum number of milliseconds to return.
  // A zero value returns all available audio (from requested start point).
  // (default is all audio, from start point)
  int64 audio_length = 6;
}

message AudioStreamPullResponse {
  // Binary audio data that was requested
  bytes audio_data = 3;
}

message SessionSetSettingsRequest {
  // Which session to set the settings for
  string session_id = 1;

  // JSON formatted settings to be configured.
  string json_settings = 3;
}

message SessionSetSettingsResponse {
  // Currently no fields returned
}

message SessionGetSettingsRequest {
  // Which session object to get the settings from
  string session_id = 1;
}

message SessionGetSettingsResponse {
  // A JSON encoded string containing the requested settings
  string json_settings = 1;
}

message InteractionCreateASRRequest {
  // The session object being referenced
  string session_id = 1;

  // List of grammar load interaction IDs, one for each root grammar to activate
  repeated string interaction_ids = 2;
}

message InteractionCreateASRResponse {
  // Interaction ID (uuid) that can be used during subsequent ASR processing
  string interaction_id = 1;
}

message InteractionCreateTTSRequest {
  // The session object being referenced
  string session_id = 1;

  // Synthesis language for this request (e.g.: "en-US", "de-DE", etc.)
  string language = 2;

  // Inline TTS definition (text and optional parameters)
  message InlineTTSRequest {
    // Text to synthesize, can simple text, or ssml
    string text = 1;

    // Optional TTS voice (if using simple text, or if not specified within
    // SSML)
    string voice = 2;
  }

  oneof tts_request {
    // URL from which to fetch synthesis request ssml
    string ssml_url = 3;

    // Inline TTS definition (text and optional parameters)
    InlineTTSRequest inline_request = 4;
  }

  // Audio format to be generated by TTS Synthesis
  AudioFormat audio_format = 10;
}

message InteractionCreateTTSResponse {
  // Interaction ID (uuid) that can be used during subsequent TTS processing
  string interaction_id = 1;
}

message InteractionCreateGrammarLoadRequest {
  // The session object being referenced
  string session_id = 1;

  // The language selector the specified grammar (e.g.: "en-US", "de-DE" or
  // dialect independent "en", "de", etc.)
  string language = 2;

  // Grammar to be loaded must be either a grammar URL, or a string containing
  // the raw grammar text
  oneof grammar_load_request {
    // A grammar URL to be loaded
    string grammar_url = 3;

    // A string containing the raw grammar text
    string inline_grammar_text = 4;
  }
}

message InteractionCreateGrammarLoadResponse {
  // Interaction ID (uuid) that can be used to reference the grammar during
  // subsequent API calls
  string interaction_id = 1;
}

message InteractionCreateGrammarParseRequest {
  // The session object being referenced
  string session_id = 1;

  // List of grammar load interaction IDs, one for each root grammar to activate
  repeated string grammar_ids = 2;

  // Input text to be parsed against the grammar[s]
  string input_text = 3;
}

message InteractionCreateGrammarParseResponse {
  // The interaction object being referenced by the request
  string interaction_id = 1;
}

message InteractionSetSettingsRequest {
  // The session object being referenced
  string session_id = 1;

  // The interaction object to set the settings for
  string interaction_id = 2;

  // JSON formatted settings to be configured.
  string json_settings = 3;
}

message InteractionSetSettingsResponse {
  // Currently no fields returned
}

message InteractionGetSettingsRequest {
  // The session object being referenced
  string session_id = 1;

  // The interaction object to get the current settings from
  string interaction_id = 2;
}

message InteractionGetSettingsResponse {
  // A JSON encoded string containing the requested settings
  string json_settings = 1;
}

message InteractionBeginProcessingRequest {
  // The session object being referenced
  string session_id = 1;

  // The interaction object being referenced
  string interaction_id = 2;
}

message InteractionBeginProcessingResponse {
  // Currently no fields returned
}

message InteractionFinalizeProcessingRequest {
  // The session object being referenced
  string session_id = 1;

  // The interaction object being referenced
  string interaction_id = 2;
}

message InteractionFinalizeProcessingResponse {
  // Currently no fields returned
}

message InteractionRequestResultsRequest {
  // The session object being referenced
  string session_id = 1;

  // The interaction object being referenced
  string interaction_id = 2;
}

message InteractionRequestResultsResponse {
  // The result status
  bool result_ready = 1;

  // The JSON object containing the result being requested or empty if
  // result_ready is false
  string results_json = 2;
}

message InteractionCancelRequest {
  // The session object being referenced
  string session_id = 1;

  // The interaction object being referenced
  string interaction_id = 2;
}

message InteractionCancelResponse {
  // Currently no fields returned
}

message InteractionCloseRequest {
  // The session object being referenced
  string session_id = 1;

  // The interaction object being referenced
  string interaction_id = 2;
}

message InteractionCloseResponse {
  // Currently no fields returned
}

// ======== Callback Messages  ===============================================

// InteractionIntermediateResultsReady
//
// Callback sent when intermediate interaction results are available.
// Call(s) to InteractionRequestResults() can be used to obtain results object.
//
message InteractionIntermediateResultsReady {
  // The session object being referenced
  string session_id = 1;

  // The interaction object being referenced
  string interaction_id = 2;
}

// InteractionFinalResultsReadyMessage
//
// Callback sent when final interaction results are ready.
// Subsequent call(s) to InteractionRequestResults() can be used to obtain
// results object.
//
// This callback signals that all processing related to this interaction is
// finished.
//
message InteractionFinalResultsReadyMessage {
  // The session object being referenced
  string session_id = 1;

  // The interaction object being referenced
  string interaction_id = 2;
}

// VADMessage
//
// Callback used to signal events over the course of Voice Activity Detection
// processing.
//
// The audio_stream_offset will signify at what point within the session audio
// stream the event occurred.
//
message VADMessage {
  // The session object being referenced
  string session_id = 1;

  // The interaction object being referenced
  string interaction_id = 2;

  enum VadMessageEventType {
    // Undefined VAD event type
    VAD_MESSAGE_EVENT_TYPE_UNSPECIFIED = 0;

    // VAD begins processing audio
    VAD_MESSAGE_EVENT_TYPE_BEGIN_PROCESSING = 1;

    // Barge-in occurred, audio that will be process by the ASR starts here
    VAD_MESSAGE_EVENT_TYPE_BARGE_IN = 2;

    // End-of-speech occurred, no further audio would be processed by VAD.
    // If the setting InteractionASR_VoiceActivityDetection.AUTO_FINALIZE_ON_EOS
    // is true, the ASR will immediately finish processing audio at this point
    VAD_MESSAGE_EVENT_TYPE_END_OF_SPEECH = 3;
  }

  // The type of event this message represents
  VadMessageEventType vad_message_type = 3;

  // The offset in milliseconds from the beginning of the stream that this
  // event occurred
  int32 audio_stream_offset = 4;
}
